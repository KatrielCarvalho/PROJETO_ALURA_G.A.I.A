{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMRbXBLMDfV/c5yQSZl2irv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KatrielCarvalho/PROJETO_ALURA_G.A.I.A/blob/main/GraficoPorImagem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Intala√ß√£o do SDK**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tihujKZT4Sh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "HMy2wzFT4R2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Importa√ß√µes** üìù\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SjxyDLnwyN2P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PbmpG-A3yKoO"
      },
      "outputs": [],
      "source": [
        "#Importa√ß√µes para o Gemini\n",
        "import pathlib as Path\n",
        "import google.generativeai as genai\n",
        "api_key = 'YOUR_API_KEY'\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "#Importa√ß√µes para os gr√°ficos\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#Importa√ß√£o de pausas\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Gera√ß√£o** ‚öô\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "5gRKKW31yT9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configura√ß√µes do Gemini\n",
        "generation_config = {\n",
        "    \"candidate_count\": 1,\n",
        "    \"temperature\": 0\n",
        "}\n",
        "\n",
        "#Seguran√ßa\n",
        "safety_settings = {\n",
        "\n",
        "    \"HARASSMENT\": \"BLOCK_LOW_AND_ABOVE\",\n",
        "    \"HATE\": \"BLOCK_LOW_AND_ABOVE\",\n",
        "    \"SEXUAL\": \"BLOCK_LOW_AND_ABOVE\",\n",
        "    \"DANGEROUS\": \"BLOCK_LOW_AND_ABOVE\"\n",
        "\n",
        "}"
      ],
      "metadata": {
        "id": "jIidRpqCyW58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**Criando o Modelo** üîß\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SIUXVbJUycKw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name = \"gemini-1.5-pro-latest\",\n",
        "                                generation_config = generation_config,\n",
        "                                safety_settings = safety_settings)\n",
        "\n",
        "#Apurando as respostas para a forma que queremos\n",
        "chat = model.start_chat(history = [\n",
        "    {\n",
        "    \"role\": \"user\",\n",
        "    \"parts\": [\"Quais itens est√£o nessa imagem?\\n\\nResposta: Bola de Basquete\\n\\n\"]\n",
        "    },\n",
        "\n",
        "    {\n",
        "    \"role\": \"user\",\n",
        "    \"parts\": [\"Quais itens est√£o nessa imagem?\\n\\nResposta: Bicicleta\\n\\n\"]\n",
        "    },\n",
        "    {\n",
        "    \"role\": \"user\",\n",
        "    \"parts\": [\"Quais itens est√£o nessa imagem?\\n\\nResposta: Carro\\n\\n\"]\n",
        "    },\n",
        "    {\n",
        "    \"role\": \"user\",\n",
        "    \"parts\": [\"Quais itens est√£o nessa imagem?\\n\\nResposta: Caderno, Caneta\\n\\n\"]\n",
        "    }\n",
        "\n",
        "])"
      ],
      "metadata": {
        "id": "7yorVMFQyejV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Analise das imagens** üßÆ\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "EBsVh_x5y6-t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Analise dos objetos*"
      ],
      "metadata": {
        "id": "bDgfG-D3vQKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def BarrasX(file):\n",
        "    i=0\n",
        "    first = True\n",
        "    prompt = genai.upload_file(file), \"Informe os itens presente nessa imagem, separados por virgula\"\n",
        "    time.sleep(2)\n",
        "    response = chat.send_message(prompt)\n",
        "    X = []\n",
        "\n",
        "    while response.text.find(\",\", i) != -1:\n",
        "        if first:\n",
        "            X.append(response.text[i : response.text.find(\",\", i)])\n",
        "            first = False\n",
        "        else:\n",
        "            X.append(response.text[i+1 : response.text.find(\",\", i)])\n",
        "        i = response.text.find(\",\", i) + 1\n",
        "\n",
        "    X.append(response.text[i+1 : len(response.text)])\n",
        "\n",
        "\n",
        "    return X"
      ],
      "metadata": {
        "id": "rKTo8R5ezLrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Analise da quantidade de cada um dos objetos*"
      ],
      "metadata": {
        "id": "SaXeIGdkvSmD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def BarrasY():\n",
        "  i=0\n",
        "  Y = []\n",
        "  prompt = \"Informe apenas o numero da quantidade de cada item respectivamente, sem espa√ßos entre as virgulas.\"\n",
        "  time.sleep(2)\n",
        "  response = chat.send_message(prompt)\n",
        "  j=0\n",
        "  while response.text.find(\",\", i) != -1:\n",
        "      Y.append(response.text[i : response.text.find(\",\", i)])\n",
        "      i = response.text.find(\",\", i) + 1\n",
        "      Y[j] = int(Y[j])\n",
        "      j+=1\n",
        "\n",
        "  Y.append(response.text[i : len(response.text)])\n",
        "  Y[j] = int(Y[j])\n",
        "\n",
        "  return Y"
      ],
      "metadata": {
        "id": "WRobY_S62l40"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inserindo a Imagem a ser analisada"
      ],
      "metadata": {
        "id": "VFwNXyYsvH1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = input(\"Insira a sua imagem: \")\n",
        "X = BarrasX(files)\n",
        "Y = BarrasY()"
      ],
      "metadata": {
        "id": "DHKFi4pqzQcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Criando o Gr√°fico** : üìä\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "9K7aMHMhvFHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use(['seaborn-v0_8-whitegrid','tableau-colorblind10'])\n",
        "fig, axes = plt.subplots(figsize=(10,5))\n",
        "plt.subplots_adjust(hspace=1)\n",
        "\n",
        "fig.suptitle('Gr√°fico por Imagem', fontsize=20, fontweight='bold', family='serif')\n",
        "axes.bar(X, Y, color = 'black')\n",
        "\n",
        "#Mostrar o Grafico\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "dNLLTt1IzYr8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}